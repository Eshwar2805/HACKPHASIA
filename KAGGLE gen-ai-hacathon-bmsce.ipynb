{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-04T23:57:36.540783Z",
     "iopub.status.busy": "2024-12-04T23:57:36.540291Z",
     "iopub.status.idle": "2024-12-04T23:57:36.560467Z",
     "shell.execute_reply": "2024-12-04T23:57:36.558928Z",
     "shell.execute_reply.started": "2024-12-04T23:57:36.540737Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/crop-recommendation/Crop_recommendation.csv\n",
      "/kaggle/input/byte-and-speak/tensorflow2/default/1/Crop_recommendation.csv\n",
      "/kaggle/input/dataset/Crop_recommendation.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T23:57:36.563461Z",
     "iopub.status.busy": "2024-12-04T23:57:36.563008Z",
     "iopub.status.idle": "2024-12-04T23:57:37.890269Z",
     "shell.execute_reply": "2024-12-04T23:57:37.888550Z",
     "shell.execute_reply.started": "2024-12-04T23:57:36.563423Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "    N   P   K  temperature   humidity        ph    rainfall label\n",
      "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
      "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
      "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
      "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
      "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2200 entries, 0 to 2199\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   N            2200 non-null   int64  \n",
      " 1   P            2200 non-null   int64  \n",
      " 2   K            2200 non-null   int64  \n",
      " 3   temperature  2200 non-null   float64\n",
      " 4   humidity     2200 non-null   float64\n",
      " 5   ph           2200 non-null   float64\n",
      " 6   rainfall     2200 non-null   float64\n",
      " 7   label        2200 non-null   object \n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 137.6+ KB\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Temperature', 'Rainfall', 'Soil_Type'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m feature_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemperature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRainfall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoil_Type\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Adjust based on your dataset\u001b[39;00m\n\u001b[1;32m     36\u001b[0m target_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrop_Type\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the actual target column in your dataset\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m y \u001b[38;5;241m=\u001b[39m df[target_column]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Split into training and testing sets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Temperature', 'Rainfall', 'Soil_Type'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Correct path to your dataset file\n",
    "data_path = '/kaggle/input/dataset/Crop_recommendation.csv'  # Replace with your actual file name\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Preview the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Handle missing values (if any)\n",
    "df = df.dropna()  # Drop rows with missing values\n",
    "\n",
    "# Encode categorical columns (e.g., soil type)\n",
    "if 'Soil_Type' in df.columns:  # Adjust if your dataset has this column\n",
    "    le = LabelEncoder()\n",
    "    df['Soil_Type'] = le.fit_transform(df['Soil_Type'])\n",
    "\n",
    "# Normalize numerical columns (e.g., temperature, rainfall)\n",
    "if {'Temperature', 'Rainfall'}.issubset(df.columns):  # Adjust based on your dataset\n",
    "    scaler = MinMaxScaler()\n",
    "    df[['Temperature', 'Rainfall']] = scaler.fit_transform(df[['Temperature', 'Rainfall']])\n",
    "\n",
    "# Split features (X) and target (y)\n",
    "feature_columns = ['Temperature', 'Rainfall', 'Soil_Type']  # Adjust based on your dataset\n",
    "target_column = 'Crop_Type'  # Replace with the actual target column in your dataset\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-04T23:57:37.891085Z",
     "iopub.status.idle": "2024-12-04T23:57:37.891458Z",
     "shell.execute_reply": "2024-12-04T23:57:37.891300Z",
     "shell.execute_reply.started": "2024-12-04T23:57:37.891282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset (adjust the path to your dataset)\n",
    "data_path = '/kaggle/input/dataset/Crop_recommendation.csv'  # Adjust with your dataset's actual path\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Preview the dataset to understand its structure\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Define feature columns and target column\n",
    "feature_columns = ['temperature', 'humidity', 'ph', 'rainfall']  # Adjust based on dataset columns\n",
    "target_column = 'label'  # Target column for crop type\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df[feature_columns]  # Feature columns (temperature, humidity, ph, rainfall)\n",
    "y = df[target_column]    # Target column (crop type)\n",
    "\n",
    "# Check the first few rows to confirm data structure\n",
    "print(\"Features (X):\")\n",
    "print(X.head())\n",
    "print(\"Target (y):\")\n",
    "print(y.head())\n",
    "\n",
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of training and testing sets\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy*100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Now the model is trained and can be used for future predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-04T23:57:37.893066Z",
     "iopub.status.idle": "2024-12-04T23:57:37.893446Z",
     "shell.execute_reply": "2024-12-04T23:57:37.893289Z",
     "shell.execute_reply.started": "2024-12-04T23:57:37.893270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset (use the correct path)\n",
    "data_path = '/kaggle/input/dataset/Crop_recommendation.csv'  # Adjust path if necessary\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Verify the columns and data\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Define feature columns and target column\n",
    "feature_columns = ['temperature', 'humidity', 'ph', 'rainfall']  # Adjust if necessary\n",
    "target_column = 'label'\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy*100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-04T23:57:37.895621Z",
     "iopub.status.idle": "2024-12-04T23:57:37.896258Z",
     "shell.execute_reply": "2024-12-04T23:57:37.895973Z",
     "shell.execute_reply.started": "2024-12-04T23:57:37.895942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data_path = '/kaggle/input/crop-recommendation/Crop_recommendation.csv'  # Update with the correct path if needed\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Step 2: Prepare the features (X) and target (y)\n",
    "# Features include N, P, K, temperature, humidity, ph, rainfall\n",
    "feature_columns = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']  # Adjust based on your dataset\n",
    "target_column = 'label'  # Assuming the crop type is the target column\n",
    "\n",
    "X = df[feature_columns]  # Feature matrix\n",
    "y = df[target_column]  # Target variable (crop type)\n",
    "\n",
    "# Step 3: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train a RandomForest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Step 7: Save the trained model to a file\n",
    "joblib.dump(model, 'crop_recommendation_model.pkl')\n",
    "\n",
    "# Step 8: Function for real-time prediction\n",
    "def recommend_crop(user_input):\n",
    "    # Assuming user_input is a dictionary with keys corresponding to feature columns\n",
    "    user_data = pd.DataFrame([user_input])\n",
    "    \n",
    "    # Load the saved model\n",
    "    model = joblib.load('crop_recommendation_model.pkl')\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_crop = model.predict(user_data)\n",
    "    \n",
    "    return predicted_crop[0]  # Return the predicted crop\n",
    "\n",
    "# Step 9: Example for real-time prediction\n",
    "user_input = {\n",
    "    'N': 90,  # Nitrogen content in the soil (example value)\n",
    "    'P': 42,  # Phosphorus content in the soil (example value)\n",
    "    'K': 43,  # Potassium content in the soil (example value)\n",
    "    'temperature': 22.5,  # Temperature in the region (example value)\n",
    "    'humidity': 80.0,  # Humidity in the region (example value)\n",
    "    'ph': 6.5,  # Soil pH value (example value)\n",
    "    'rainfall': 200.0  # Rainfall in the region (example value)\n",
    "}\n",
    "\n",
    "# Predict the most suitable crop for the given region and soil type\n",
    "predicted_crop = recommend_crop(user_input)\n",
    "print(f\"The most suitable crop for the given conditions is: {predicted_crop}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T23:58:00.773350Z",
     "iopub.status.busy": "2024-12-04T23:58:00.772878Z",
     "iopub.status.idle": "2024-12-04T23:58:37.343122Z",
     "shell.execute_reply": "2024-12-04T23:58:37.341428Z",
     "shell.execute_reply.started": "2024-12-04T23:58:00.773314Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 99.32%\n",
      "Please enter the following details about your region and soil:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Nitrogen content in the soil (N):  67\n",
      "Enter the Phosphorus content in the soil (P):  78\n",
      "Enter the Potassium content in the soil (K):  54\n",
      "Enter the temperature in the region (°C):  23\n",
      "Enter the humidity in the region (%):  67\n",
      "Enter the pH of the soil:  6\n",
      "Enter the rainfall in the region (mm):  230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most suitable crop for the given conditions is: banana\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data_path = '/kaggle/input/crop-recommendation/Crop_recommendation.csv'  # Update with the correct path if needed\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Step 2: Prepare the features (X) and target (y)\n",
    "feature_columns = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']\n",
    "target_column = 'label'  # Assuming the crop type is the target column\n",
    "\n",
    "X = df[feature_columns]  # Feature matrix\n",
    "y = df[target_column]  # Target variable (crop type)\n",
    "\n",
    "# Step 3: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train a RandomForest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Step 7: Save the trained model to a file\n",
    "joblib.dump(model, 'crop_recommendation_model.pkl')\n",
    "\n",
    "# Step 8: Function for real-time prediction\n",
    "def recommend_crop(user_input):\n",
    "    # Assuming user_input is a dictionary with keys corresponding to feature columns\n",
    "    user_data = pd.DataFrame([user_input])\n",
    "    \n",
    "    # Load the saved model\n",
    "    model = joblib.load('crop_recommendation_model.pkl')\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_crop = model.predict(user_data)\n",
    "    \n",
    "    return predicted_crop[0]  # Return the predicted crop\n",
    "\n",
    "# Step 9: Get user input for location (temperature, humidity) and soil type (N, P, K, ph, rainfall)\n",
    "def get_user_input():\n",
    "    print(\"Please enter the following details about your region and soil:\")\n",
    "    \n",
    "    # Get the user's location and soil type (N, P, K, temperature, humidity, ph, rainfall)\n",
    "    N = float(input(\"Enter the Nitrogen content in the soil (N): \"))\n",
    "    P = float(input(\"Enter the Phosphorus content in the soil (P): \"))\n",
    "    K = float(input(\"Enter the Potassium content in the soil (K): \"))\n",
    "    temperature = float(input(\"Enter the temperature in the region (°C): \"))\n",
    "    humidity = float(input(\"Enter the humidity in the region (%): \"))\n",
    "    ph = float(input(\"Enter the pH of the soil: \"))\n",
    "    rainfall = float(input(\"Enter the rainfall in the region (mm): \"))\n",
    "    \n",
    "    user_input = {\n",
    "        'N': N,\n",
    "        'P': P,\n",
    "        'K': K,\n",
    "        'temperature': temperature,\n",
    "        'humidity': humidity,\n",
    "        'ph': ph,\n",
    "        'rainfall': rainfall\n",
    "    }\n",
    "    \n",
    "    return user_input\n",
    "\n",
    "# Step 10: Example usage for real-time prediction\n",
    "user_input = get_user_input()\n",
    "predicted_crop = recommend_crop(user_input)\n",
    "print(f\"The most suitable crop for the given conditions is: {predicted_crop}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6230934,
     "sourceId": 10102089,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6230976,
     "sourceId": 10102142,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 183169,
     "modelInstanceId": 160776,
     "sourceId": 188586,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
